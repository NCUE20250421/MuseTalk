# UI.py
# ä½¿ç”¨ Gradio å‰µå»ºç”¨æˆ·ç•Œé¢ï¼Œé›†æˆ LLMã€TTS å’Œè¦–é »ç”Ÿæˆæ¨¡çµ„

import os
import gradio as gr
import tempfile
from llm_module import generate_text
from tts_module import text_to_speech, get_taiwanese_voices
from video_module import generate_video, preload_models
import time
import datetime

# è¨­ç½®æ¨¡å‹è·¯å¾‘
MODEL_PATHS = {
    "unet_model_path": "./models/musetalkV15/unet.pth",
    "unet_config": "./models/musetalkV15/musetalk.json",
    "whisper_dir": "./models/whisper"
}

# å¯ç”¨çš„è¦–é »æ¨¡æ¿
VIDEO_TEMPLATES = {
    "å­«ç‡•å§¿": "assets/demo/sun1/sun.png",
    "è’™å¨œéº—è": "assets/demo/monalisa/monalisa.png",
    "ä¼Šéš†é¦¬æ–¯å…‹": "assets/demo/musk/musk.png",
    "æ™®é€šç”·æ€§": "assets/demo/man/man.png"
}

# å¯ç”¨çš„ TTS è²éŸ³
TTS_VOICES = {
    "å¥³æ€§è²éŸ³ (æ›‰è‡»)": "zh-TW-HsiaoChenNeural",
    "ç”·æ€§è²éŸ³ (é›²å“²)": "zh-TW-YunJheNeural",
    "å¥³å­©è²éŸ³ (æ›‰ç‰)": "zh-TW-HsiaoYuNeural"
}

# å‰µå»ºè¼¸å‡ºç›®éŒ„ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
os.makedirs("./outputs", exist_ok=True)

# æ ¼å¼åŒ–æ™‚é–“å‡½æ•¸
def format_time(seconds):
    """å°‡ç§’æ•¸æ ¼å¼åŒ–ç‚ºæ˜“è®€çš„æ™‚é–“æ ¼å¼"""
    return str(datetime.timedelta(seconds=round(seconds)))

# é è¼‰å…¥ MuseTalk æ¨¡å‹
print("æ­£åœ¨é å…ˆè¼‰å…¥ MuseTalk æ¨¡å‹ï¼Œè«‹ç¨å€™...")
start_time = time.time()
models_loaded = preload_models(
    unet_model_path=MODEL_PATHS["unet_model_path"],
    unet_config=MODEL_PATHS["unet_config"],
    whisper_dir=MODEL_PATHS["whisper_dir"]
)
model_load_time = time.time() - start_time
print(f"MuseTalk æ¨¡å‹é è¼‰ç‹€æ…‹: {'æˆåŠŸ' if models_loaded else 'å¤±æ•—'}, è€—æ™‚: {format_time(model_load_time)}")

# ç”Ÿæˆæ­¡è¿èªéŸ³å’Œè¦–é »
def generate_welcome_assets():
    """
    ç”Ÿæˆæ­¡è¿èªéŸ³å’Œè¦–é »ï¼Œç”¨æ–¼ç³»çµ±é ç†±
    """
    print("æ­£åœ¨ç”Ÿæˆæ­¡è¿èªéŸ³å’Œè¦–é »...")
    welcome_text = "æ­¡è¿ä½¿ç”¨æ•¸ä½å¸å„€ç³»çµ±"
    welcome_audio_path = "./outputs/welcome_audio.mp3"
    welcome_video_path = "./outputs/welcome_video.mp4"
    
    total_start_time = time.time()
    
    # ç”Ÿæˆæ­¡è¿èªéŸ³
    try:
        tts_start_time = time.time()
        audio_path = text_to_speech(
            text=welcome_text,
            output_file=welcome_audio_path,
            voice="zh-TW-HsiaoChenNeural"  # ä½¿ç”¨å¥³æ€§è²éŸ³
        )
        tts_time = time.time() - tts_start_time
        print(f"æ­¡è¿èªéŸ³ç”ŸæˆæˆåŠŸ: {audio_path}, è€—æ™‚: {format_time(tts_time)}")
        
        # å¦‚æœæ¨¡å‹å·²é è¼‰ï¼Œç”Ÿæˆæ­¡è¿è¦–é »
        if models_loaded:
            # ä½¿ç”¨å­«ç‡•å§¿æ¨¡æ¿ç”Ÿæˆæ­¡è¿è¦–é »
            video_start_time = time.time()
            video_template = VIDEO_TEMPLATES["å­«ç‡•å§¿"]
            video_path = generate_video(
                audio_file=audio_path,
                video_path=video_template,
                output_path=welcome_video_path,
                use_preloaded_models=True  # ä½¿ç”¨é å…ˆè¼‰å…¥çš„æ¨¡å‹
            )
            video_time = time.time() - video_start_time
            total_time = time.time() - total_start_time
            
            print(f"æ­¡è¿è¦–é »ç”ŸæˆæˆåŠŸ: {video_path}, è€—æ™‚: {format_time(video_time)}")
            print(f"æ­¡è¿è³‡æºç”Ÿæˆç¸½è€—æ™‚: {format_time(total_time)}")
            return welcome_text, audio_path, video_path, tts_time, video_time
        
        total_time = time.time() - total_start_time
        print(f"æ­¡è¿è³‡æºç”Ÿæˆç¸½è€—æ™‚: {format_time(total_time)}")
        return welcome_text, audio_path, None, tts_time, 0
    except Exception as e:
        print(f"æ­¡è¿è³‡æºç”Ÿæˆå¤±æ•—: {e}")
        return "æ­¡è¿ä½¿ç”¨æ•¸ä½å¸å„€ç³»çµ±", None, None, 0, 0

# ç”Ÿæˆæ­¡è¿è³‡æº
welcome_text, welcome_audio, welcome_video, welcome_tts_time, welcome_video_time = generate_welcome_assets()

def process_query(query, selected_template, selected_voice, progress=gr.Progress()):
    """
    è™•ç†ç”¨æˆ·æŸ¥è©¢çš„å®Œæ•´æµç¨‹ï¼šLLM â†’ TTS â†’ è¦–é »ç”Ÿæˆ
    """
    # ç²å–å¯¦éš›çš„ TTS èªéŸ³ ID
    voice_id = TTS_VOICES[selected_voice]
    
    # è¨˜éŒ„ç¸½è™•ç†é–‹å§‹æ™‚é–“
    total_start_time = time.time()
    
    # æ­¥é©Ÿ 1: ä½¿ç”¨ LLM ç”Ÿæˆæ–‡æœ¬
    progress(0.1, "ä½¿ç”¨ LLM ç”Ÿæˆå›æ‡‰ä¸­...")
    llm_start_time = time.time()
    try:
        llm_output = generate_text(query)
        llm_time = time.time() - llm_start_time
        llm_output_with_time = f"{llm_output}\n\n[LLM è€—æ™‚: {format_time(llm_time)}]"
    except Exception as e:
        llm_time = time.time() - llm_start_time
        error_msg = f"LLM éŒ¯èª¤: {str(e)}\n[è€—æ™‚: {format_time(llm_time)}]"
        return error_msg, None, None, {"llm": llm_time, "tts": 0, "video": 0, "total": llm_time}
    
    # æ­¥é©Ÿ 2: ä½¿ç”¨ TTS ç”ŸæˆéŸ³é »
    progress(0.3, "å°‡æ–‡æœ¬è½‰æ›ç‚ºèªéŸ³ä¸­...")
    tts_start_time = time.time()
    try:
        timestamp = int(time.time())
        audio_file = f"./outputs/audio_{timestamp}.mp3"
        audio_path = text_to_speech(
            text=llm_output,
            output_file=audio_file,
            voice=voice_id
        )
        tts_time = time.time() - tts_start_time
        llm_output_with_time += f"\n[TTS è€—æ™‚: {format_time(tts_time)}]"
    except Exception as e:
        tts_time = time.time() - tts_start_time
        total_time = time.time() - total_start_time
        error_msg = f"{llm_output_with_time}\nTTS éŒ¯èª¤: {str(e)}\n[è€—æ™‚: {format_time(tts_time)}]"
        return error_msg, None, None, {"llm": llm_time, "tts": tts_time, "video": 0, "total": total_time}
    
    # æ­¥é©Ÿ 3: ç”Ÿæˆè¦–é »
    progress(0.6, "ç”Ÿæˆå˜´å‹åŒæ­¥è¦–é »ä¸­...")
    video_start_time = time.time()
    try:
        video_file = f"./outputs/video_{timestamp}.mp4"
        video_template = VIDEO_TEMPLATES[selected_template]
        
        video_path = generate_video(
            audio_file=audio_path,
            video_path=video_template,
            bbox_shift=0,
            extra_margin=10,
            output_path=video_file,
            unet_model_path=MODEL_PATHS["unet_model_path"],
            unet_config=MODEL_PATHS["unet_config"],
            whisper_dir=MODEL_PATHS["whisper_dir"],
            use_preloaded_models=True  # ä½¿ç”¨é å…ˆè¼‰å…¥çš„æ¨¡å‹
        )
        video_time = time.time() - video_start_time
        total_time = time.time() - total_start_time
        
        llm_output_with_time += f"\n[è¦–é »ç”Ÿæˆè€—æ™‚: {format_time(video_time)}]\n[ç¸½è€—æ™‚: {format_time(total_time)}]"
    except Exception as e:
        video_time = time.time() - video_start_time
        total_time = time.time() - total_start_time
        error_msg = f"{llm_output_with_time}\nè¦–é »ç”ŸæˆéŒ¯èª¤: {str(e)}\n[è€—æ™‚: {format_time(video_time)}]\n[ç¸½è€—æ™‚: {format_time(total_time)}]"
        return error_msg, audio_path, None, {"llm": llm_time, "tts": tts_time, "video": video_time, "total": total_time}
    
    progress(1.0, "è™•ç†å®Œæˆ!")
    
    # è¿”å›è™•ç†çµæœå’Œå„éƒ¨åˆ†è€—æ™‚
    time_stats = {
        "llm": llm_time,
        "tts": tts_time,
        "video": video_time,
        "total": total_time
    }
    
    return llm_output_with_time, audio_path, video_path, time_stats

def build_interface():
    """
    æ§‹å»º Gradio ç•Œé¢
    """
    with gr.Blocks(title="MuseTalk æ•¸ä½å¸å„€ç³»çµ±", theme=gr.themes.Soft()) as interface:
        gr.Markdown("# MuseTalk æ•¸ä½å¸å„€ç³»çµ±")
        gr.Markdown("è¼¸å…¥æ‚¨çš„å•é¡Œï¼Œç³»çµ±å°‡ç”Ÿæˆæ–‡æœ¬å›æ‡‰ä¸¦å‰µå»ºå°æ‡‰çš„è¦–é »")
        
        if models_loaded:
            gr.Markdown(f"âœ… MuseTalk æ¨¡å‹å·²é å…ˆè¼‰å…¥ï¼Œè¦–é »ç”Ÿæˆé€Ÿåº¦å°‡å¤§å¹…æå‡ (è¼‰å…¥è€—æ™‚: {format_time(model_load_time)})")
        else:
            gr.Markdown("âš ï¸ MuseTalk æ¨¡å‹é è¼‰å…¥å¤±æ•—ï¼Œå°‡ä½¿ç”¨æ¨™æº–æ¨¡å¼")
        
        # ç¬¬ä¸€è¡Œï¼šè¼¸å…¥å€åŸŸ
        with gr.Row():
            query_input = gr.Textbox(
                label="æ‚¨çš„å•é¡Œ", 
                placeholder="è«‹è¼¸å…¥æ‚¨æƒ³å•çš„å•é¡Œ...",
                lines=3,
                value=""  # æ¸…ç©ºåˆå§‹å€¼
            )
        
        # ç¬¬äºŒè¡Œï¼šé¸é …å’Œæäº¤æŒ‰éˆ•
        with gr.Row():
            template_dropdown = gr.Dropdown(
                choices=list(VIDEO_TEMPLATES.keys()),
                value=list(VIDEO_TEMPLATES.keys())[0],
                label="é¸æ“‡è¦–é »æ¨¡æ¿"
            )
            voice_dropdown = gr.Dropdown(
                choices=list(TTS_VOICES.keys()),
                value=list(TTS_VOICES.keys())[0],
                label="é¸æ“‡èªéŸ³"
            )
            submit_btn = gr.Button("ç”Ÿæˆè¦–é »", variant="primary")
        
        # ç¬¬ä¸‰è¡Œï¼šè¼¸å‡ºå€åŸŸ - AIæ–‡æœ¬å’ŒéŸ³é »åœ¨å·¦å´ï¼Œè¦–é »åœ¨å³å´
        with gr.Row():
            # å·¦å´ï¼šæ–‡æœ¬å’ŒéŸ³é »
            with gr.Column(scale=1):
                # è¼¸å‡ºå€åŸŸ - é è¨­é¡¯ç¤ºæ­¡è¿å…§å®¹
                welcome_text_with_time = f"æ­¡è¿ä½¿ç”¨æ•¸ä½å¸å„€ç³»çµ±\n\n[TTS è€—æ™‚: {format_time(welcome_tts_time)}]\n[è¦–é »ç”Ÿæˆè€—æ™‚: {format_time(welcome_video_time)}]"
                llm_output = gr.Textbox(
                    label="AI å›æ‡‰æ–‡æœ¬", 
                    lines=5,
                    value=welcome_text_with_time
                )
                audio_output = gr.Audio(
                    label="ç”Ÿæˆçš„éŸ³é »",
                    value=welcome_audio if welcome_audio else None
                )
                
                # æ·»åŠ è€—æ™‚çµ±è¨ˆåœ–è¡¨
                time_stats = gr.Json(label="è™•ç†è€—æ™‚çµ±è¨ˆ", visible=False)
                
            # å³å´ï¼šè¦–é »
            with gr.Column(scale=1):
                video_output = gr.Video(
                    label="ç”Ÿæˆçš„è¦–é »",
                    value=welcome_video if welcome_video else None
                )
        
        # è™•ç†æäº¤
        submit_btn.click(
            fn=process_query,
            inputs=[
                query_input,
                template_dropdown,
                voice_dropdown
            ],
            outputs=[
                llm_output,
                audio_output, 
                video_output,
                time_stats
            ]
        )
        
        # ç¯„ä¾‹
        gr.Examples(
            examples=[
                ["ä»‹ç´¹ä¸€ä¸‹å°ç£çš„å¤œå¸‚æ–‡åŒ–", "å­«ç‡•å§¿", "å¥³æ€§è²éŸ³ (æ›‰è‡»)"],
                ["è«‹åˆ†äº«ä¸€äº›é—œæ–¼å°åŒ—101çš„æ­·å²", "ä¼Šéš†é¦¬æ–¯å…‹", "ç”·æ€§è²éŸ³ (é›²å“²)"],
                ["å°ç£æœ‰å“ªäº›è‘—åçš„å°åƒï¼Ÿ", "è’™å¨œéº—è", "å¥³å­©è²éŸ³ (æ›‰ç‰)"]
            ],
            inputs=[query_input, template_dropdown, voice_dropdown]
        )
        
        gr.Markdown("## ä½¿ç”¨èªªæ˜")
        gr.Markdown("""
        1. åœ¨æ–‡æœ¬æ¡†ä¸­è¼¸å…¥æ‚¨æƒ³å•çš„å•é¡Œ
        2. é¸æ“‡æƒ³è¦ä½¿ç”¨çš„è¦–é »æ¨¡æ¿å’ŒèªéŸ³é¡å‹
        3. é»æ“Šã€Œç”Ÿæˆè¦–é »ã€æŒ‰éˆ•
        4. ç­‰å¾…ç³»çµ±ç”Ÿæˆæ–‡æœ¬ã€éŸ³é »å’Œè¦–é »
        5. æ‚¨å¯ä»¥ä¸‹è¼‰ç”Ÿæˆçš„éŸ³é »å’Œè¦–é »
        
        ğŸ’¡ **å„ªåŒ–æç¤º**: ç³»çµ±å·²é å…ˆè¼‰å…¥æ¨¡å‹ï¼Œé¦–æ¬¡ç”Ÿæˆè¦–é »å¾Œï¼Œå¾ŒçºŒè™•ç†é€Ÿåº¦æœƒå¤§å¹…æå‡ï¼
        """)
        
    return interface

# å•Ÿå‹• Gradio ç•Œé¢
if __name__ == "__main__":
    interface = build_interface()
    interface.launch(share=True)